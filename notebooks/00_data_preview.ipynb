{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preview - HAR Theft Detection\n",
    "\n",
    "This notebook helps you visualize the dataset and verify data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.datasets import VideoClipDataset, create_dummy_dataset\n",
    "from src.transforms import VideoTransform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy Dataset (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small dummy dataset\n",
    "train_csv, val_csv = create_dummy_dataset(\n",
    "    output_dir='../data',\n",
    "    num_videos_per_class=5,\n",
    "    num_frames=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "dataset = VideoClipDataset(\n",
    "    metadata_csv=train_csv,\n",
    "    clips_dir='../data/clips',\n",
    "    num_frames=32,\n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Classes: {dataset.labels}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(dataset.metadata['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clip(clip_tensor, label, num_frames_to_show=8):\n",
    "    \"\"\"Visualize frames from a video clip\"\"\"\n",
    "    # clip_tensor shape: (T, C, H, W)\n",
    "    T = clip_tensor.shape[0]\n",
    "    indices = np.linspace(0, T-1, num_frames_to_show, dtype=int)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        frame = clip_tensor[idx].permute(1, 2, 0).numpy()\n",
    "        # Denormalize\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        frame = frame * std + mean\n",
    "        frame = np.clip(frame, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(frame)\n",
    "        axes[i].set_title(f'Frame {idx}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Label: {label}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from each class\n",
    "for class_name in dataset.labels:\n",
    "    # Find a sample from this class\n",
    "    class_idx = dataset.label_to_idx[class_name]\n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        if sample['label'] == class_idx:\n",
    "            visualize_clip(sample['video'], class_name)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Get a batch\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "print(f\"Batch video shape: {batch['video'].shape}\")\n",
    "print(f\"Batch labels: {batch['label']}\")\n",
    "print(f\"Batch clip IDs: {batch['clip_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for imbalanced data\n",
    "class_weights = dataset.get_class_weights()\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for class_name, weight in zip(dataset.labels, class_weights):\n",
    "    print(f\"  {class_name}: {weight:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
